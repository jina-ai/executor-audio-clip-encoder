__copyright__ = "Copyright (c) 2020-2021 Jina AI Limited. All rights reserved."
__license__ = "Apache-2.0"

from typing import Optional, Iterable, Any

from jina import Executor, DocumentArray, requests
import torch

from model import AudioCLIP
from utils.transforms import ToTensor1D
from jina_commons.batching import get_docs_batch_generator

class AudioCLIPEncoder(Executor):
    """
     Encode audio data with AudioCLIP embeddings
     :param model_path: path of the pre-trained AudioCLP model
     :param default_traversal_paths: fallback batch size in case there is not batch size sent in the request
     """

    def __init__(self,
                 model_path: str = 'assets/AudioCLIP-Full-Training.pt',
                 default_batch_size: int = 32,
                 default_traversal_paths: Iterable[str] = ['r'],
                 *args, **kwargs):

        super().__init__(*args, **kwargs)
        torch.set_grad_enabled(False)
        self.model_path = model_path
        self.aclp = AudioCLIP(pretrained=model_path)
        self.audio_transforms = ToTensor1D()
        self.default_traversal_paths = default_traversal_paths
        self.default_batch_size = default_batch_size

    @requests
    def encode(self, docs: Optional[DocumentArray], parameters: dict, *args, **kwargs) -> Any:

        if docs:
            cleaned_document_array = self._get_input_data(docs, parameters)
            document_batches_generator = get_docs_batch_generator(
                cleaned_document_array,
                traversal_path=parameters.get('traversal_paths', self.default_traversal_paths),
                batch_size=parameters.get('batch_size', self.default_batch_size),
                needs_attr='blob',
            )
            self._create_embeddings(document_batches_generator)

    def _get_input_data(self, docs: DocumentArray, parameters: dict):
        """Create a filtered set of Documents to iterate over."""
        # filter out documents without images
        filtered_docs = DocumentArray([doc for doc in docs if doc.blob is not None])

        return filtered_docs

    def _create_embeddings(self, document_batches_generator: Iterable):
        """Update the documents with the embeddings generated by AudioCLIP"""

        for document_batch in document_batches_generator:
            audio = torch.stack([self.audio_transforms(d.blob.reshape(1, -1)) for d in document_batch])
            ((embedding_batch, _, _), _), _ = self.aclp(audio=audio)
            embedding_batch = embedding_batch / torch.linalg.norm(embedding_batch, dim=-1, keepdim=True)
            numpy_embedding_batch = embedding_batch.cpu().numpy()
            for document, numpy_embedding in zip(document_batch, numpy_embedding_batch):
                document.embedding = numpy_embedding
